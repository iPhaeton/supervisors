{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pyramda import compose, curry\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cast = curry(tf.cast)\n",
    "tf_add = curry(tf.add)\n",
    "tf_multiply = curry(tf.multiply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_labels = compose(\n",
    "    list,\n",
    "    range,\n",
    "    len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list(refs, condition, l):\n",
    "    if condition == True:\n",
    "        return list(filter(lambda x: x in refs, l))\n",
    "    else:\n",
    "        return list(filter(lambda x: x not in refs, l))\n",
    "    \n",
    "filter_list = curry(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(path, dirs, labels, num_per_class, image_shape):\n",
    "    \"\"\"\n",
    "    Loads a random batch of images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path: string\n",
    "        Path to the image source directory on disk. \n",
    "        Source directory should be divided into directories, one directory per class.\n",
    "    - dirs: [string]\n",
    "        List of directories contained in the path (classes).\n",
    "    - labels: [int]\n",
    "        Class labels. Should correspond to classes.\n",
    "    - num_per_class: int\n",
    "        Number of images randomly chosen from each class\n",
    "    - image_shape: tuple (H,W,C)\n",
    "        H - image height\n",
    "        W - image width\n",
    "        C - number of channels\n",
    "      \n",
    "    Returns:\n",
    "    --------\n",
    "    - samples: ndarray (N, H, W, C)\n",
    "        Numpy array of randomly chosen images resized according to model's input shape.\n",
    "        N - number of samples\n",
    "        H - height\n",
    "        W - width\n",
    "        C - number of channels\n",
    "    - batch_labels: [int]\n",
    "        Sample labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = np.zeros((num_per_class * len(dirs), *image_shape))\n",
    "    batch_labels = np.ones(num_per_class * len(dirs)).astype(int)\n",
    "    \n",
    "    for i, dir_name in enumerate(tqdm(dirs)):\n",
    "        dir_path = os.path.join(path, dir_name)\n",
    "        filenames = os.listdir(dir_path)\n",
    "        filenames = np.random.choice(filenames, num_per_class)\n",
    "        \n",
    "        batch = np.zeros((num_per_class, *image_shape))\n",
    "\n",
    "        for j, filename in enumerate(filenames):\n",
    "            img = Image.open(os.path.join(dir_path, filename))\n",
    "            img = img.resize((image_shape[1], image_shape[0]))\n",
    "            img = np.array(img)\n",
    "            batch[j,:,:,:] = img\n",
    "        \n",
    "        samples[i*num_per_class: i*num_per_class + num_per_class, :, :, :] = batch\n",
    "        batch_labels[i*num_per_class: i*num_per_class + num_per_class] = batch_labels[i*num_per_class: i*num_per_class + num_per_class] * labels[i]\n",
    "    \n",
    "    return samples, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.09it/s]\n"
     ]
    }
   ],
   "source": [
    "path = '../input/mars/bbox_train/'\n",
    "dirs = compose(\n",
    "    filter_list(['.DS_Store'], False),\n",
    "    os.listdir,\n",
    ")(path)\n",
    "labels = classes_to_labels(dirs)\n",
    "\n",
    "samples, labels = load_batch(path, dirs[0:5], labels, num_per_class=5, image_shape=(128, 64, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_filename, input_name=\"images\", output_name=\"features\"):\n",
    "    \"\"\"\n",
    "    Load a model from\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - checkpoint_filename: string\n",
    "        Path to the checkpoint on disk.\n",
    "    - input_name: string\n",
    "        Name of the input variable in the graph.\n",
    "    - output_name: string\n",
    "        Name of the output variable in the graph.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    - inputs: Tensor (N, H, W, C)\n",
    "        Images\n",
    "        N - number of samples (None)\n",
    "        H - image height\n",
    "        W - image width\n",
    "        C - number of channels\n",
    "    - outputs: Tensor (N, E)\n",
    "        Image embeddings\n",
    "        N - number of samples (None)\n",
    "        E - embedding size\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(file_handle.read())\n",
    "    \n",
    "    tf.import_graph_def(graph_def, name=\"net\")\n",
    "    \n",
    "    inputs = tf.get_default_graph().get_tensor_by_name(\"net/%s:0\" % input_name)\n",
    "    outputs = tf.get_default_graph().get_tensor_by_name(\"net/%s:0\" % output_name)\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_mask(labels):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - labels: [int]\n",
    "        List of labels of size N (number of samples).\n",
    "    Returns:\n",
    "    ----------\n",
    "    - positive_mask: Tensor (N, N)\n",
    "        A square martix with True for all positive samples and False for all negative samples.\n",
    "    \"\"\"\n",
    "    return tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "get_not_anchor_mask = compose(\n",
    "    tf.logical_not,\n",
    "    tf_cast(dtype = tf.bool),\n",
    "    tf.eye,\n",
    "    lambda shape: shape[0],\n",
    "    tf.shape,\n",
    ")\n",
    "\n",
    "get_not_anchor_mask.__doc__ = \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - labels: [int]\n",
    "        List of labels of size N (number of samples).\n",
    "    Returns:\n",
    "    ----------\n",
    "    - not_anchor_mask: Tensor (N, N)\n",
    "        A square martix with False for all anchors and True for other samples, like\n",
    "        [[0 1 1]\n",
    "         [1 0 1]\n",
    "         [1 1 0]]\n",
    "\"\"\"\n",
    "\n",
    "def get_anchor_positive_mask(labels):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - labels: [int]\n",
    "        List of labels of size N (number of samples).\n",
    "    Returns:\n",
    "    ----------\n",
    "    - anchor_positive_mask: Tensor (N, N)\n",
    "        A square martix with ones for all positive samples, except anchors on main diagonal, \n",
    "        and zeros for all other samples.\n",
    "    \"\"\"\n",
    "    return tf.to_float(\n",
    "        tf.logical_and(\n",
    "            get_not_anchor_mask(labels),\n",
    "            get_positive_mask(labels),\n",
    "        )\n",
    "    )\n",
    "\n",
    "get_negative_mask = compose(\n",
    "    tf_add(1.),\n",
    "    tf_multiply(sys.float_info.max),\n",
    "    tf.to_float,\n",
    "    get_positive_mask,\n",
    ")\n",
    "\n",
    "get_negative_mask.__doc__ = \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - labels: [int]\n",
    "        List of labels of size N (number of samples).\n",
    "    Returns:\n",
    "    ----------\n",
    "    - positive_mask: Tensor (N, N)\n",
    "        A square martix with ones for all negative samples and infinity for all positive samples.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(embeddings):\n",
    "    \"\"\"\n",
    "    Compute cosine distance matrix\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - embeddings: Tensor(N, E)\n",
    "        Image embeddings, outputs of the convolutional network.\n",
    "        N - number of samples (None)\n",
    "        E - embedding size\n",
    "    \"\"\"\n",
    "    \n",
    "    normalized_embeddings = tf.divide(\n",
    "        embeddings,\n",
    "        tf.norm(embeddings),\n",
    "    )\n",
    "    \n",
    "    return tf.subtract(\n",
    "        1.,\n",
    "        tf.matmul(normalized_embeddings, tf.transpose(normalized_embeddings))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, metric, masks, margin):\n",
    "    \"\"\"\n",
    "    Compute triplet loss\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - model: tuple\n",
    "        Model input tensor and model output tensor\n",
    "    - metric: function\n",
    "        Should take output tesor as a parameter and compute distance matrix\n",
    "    - masks: tuple\n",
    "        Contains two matrices: \n",
    "            a square martix with ones for all positive samples, except anchors on main diagonal, \n",
    "            and zeros for all other samples;\n",
    "            a square martix with ones for all negative samples and infinity \n",
    "            for all positive samples.\n",
    "    - margin: float\n",
    "        Minimum margin between positive and negative distance.\n",
    "    \"\"\"\n",
    "    inputs, outputs = model\n",
    "    anchor_positive_mask, negative_mask = masks\n",
    "\n",
    "    distances = metric(outputs)\n",
    "    positive_distances = tf.multiply(anchor_positive_mask, distances)\n",
    "    negative_distances = tf.multiply(negative_mask, distances)\n",
    "\n",
    "    loss = tf.expand_dims(positive_distances, 2) - tf.expand_dims(negative_distances, 1) + margin\n",
    "    loss = tf.maximum(loss, 0.)\n",
    "    \n",
    "    num_triplets = compose(\n",
    "        tf.reduce_sum,\n",
    "        tf.to_float,\n",
    "    )(tf.greater(loss, 0.))\n",
    "    \n",
    "    loss = tf.reduce_sum(loss) / (num_triplets + 1e-16)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./models/deep_sort_cnn/mars-small128.pb')\n",
    "anchor_positive_mask = get_anchor_positive_mask(labels)\n",
    "negetive_mask = get_negative_mask(labels)\n",
    "\n",
    "compute_loss(\n",
    "    model, \n",
    "    cosine_distance, \n",
    "    masks=(anchor_positive_mask, negetive_mask), \n",
    "    margin=0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
