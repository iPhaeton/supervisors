{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pyramda import compose, curry\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from visuazlizers.nb_graph_visualizer import show_graph, rename_nodes\n",
    "from utils.curried_functions import tf_add, tf_cast, tf_multiply, filter_list\n",
    "from loaders import load_batch_of_images, load_model_pb\n",
    "from siamese import compute_loss, get_anchor_positive_mask, get_negative_mask, train_siamese_model\n",
    "from utils.metrics import cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_labels = compose(\n",
    "    list,\n",
    "    range,\n",
    "    len,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from input.models.deep_sort_cnn.freeze_model import _preprocess, _network_factory\n",
    "\n",
    "def create_deep_sort_cnn_graph():\n",
    "    input_var = tf.placeholder(tf.uint8, (None, 128, 64, 3), name=\"images\")\n",
    "    image_var = tf.map_fn(\n",
    "        lambda x: _preprocess(x), tf.cast(input_var, tf.float32),\n",
    "        back_prop=False\n",
    "    )\n",
    "\n",
    "    factory_fn = _network_factory()\n",
    "    features, _ = factory_fn(image_var, reuse=None)\n",
    "    features = tf.identity(features, name=\"features\")\n",
    "    \n",
    "    return input_var, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2_1/1/Elu:0/activations is illegal; using conv2_1/1/Elu_0/activations instead.\n",
      "INFO:tensorflow:Summary name conv2_3/1/Elu:0/activations is illegal; using conv2_3/1/Elu_0/activations instead.\n",
      "INFO:tensorflow:Summary name conv3_1/1/Elu:0/activations is illegal; using conv3_1/1/Elu_0/activations instead.\n",
      "INFO:tensorflow:Summary name conv3_3/1/Elu:0/activations is illegal; using conv3_3/1/Elu_0/activations instead.\n",
      "INFO:tensorflow:Summary name conv4_1/1/Elu:0/activations is illegal; using conv4_1/1/Elu_0/activations instead.\n",
      "INFO:tensorflow:Summary name conv4_3/1/Elu:0/activations is illegal; using conv4_3/1/Elu_0/activations instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 20.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss 0.199428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 4/18 [00:00<00:00, 30.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 20.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss 0.200007\n",
      "Validation loss 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "source_path = '../input/mars/bbox_train/'\n",
    "dirs = compose(\n",
    "    filter_list(['.DS_Store'], False),\n",
    "    os.listdir,\n",
    ")(source_path)\n",
    "\n",
    "labels = classes_to_labels(dirs)\n",
    "train_dirs, val_dirs, train_labels, val_labels = train_test_split(dirs[0:20], labels[0:20], test_size=0.1)\n",
    "\n",
    "inputs, outputs, _ = load_model_pb(\n",
    "    '../input/models/deep_sort_cnn/mars-small128.pb', \n",
    "    input_name=\"images\", \n",
    "    output_name=\"features\", \n",
    "    graph_creator=create_deep_sort_cnn_graph,\n",
    ")\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "train_siamese_model(\n",
    "    session=session,\n",
    "    model=[inputs, outputs],\n",
    "    source_path=source_path,\n",
    "    dirs=(train_dirs, val_dirs),\n",
    "    class_labels=(train_labels, val_labels),\n",
    "    metric=cosine_distance,\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.00001),\n",
    "    batch_loader=load_batch_of_images(image_shape=(128, 64, 3)),\n",
    "    num_iter=2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
