{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from pyramda import compose, curry\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list(refs, condition, l):\n",
    "    if condition == True:\n",
    "        return list(filter(lambda x: x in refs, l))\n",
    "    else:\n",
    "        return list(filter(lambda x: x not in refs, l))\n",
    "    \n",
    "filter_list = curry(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(a, b):\n",
    "    return 1 - np.dot(a, b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = curry(tf.add)\n",
    "subtract_from = curry(tf.subtract)\n",
    "matmul = curry(tf.matmul)\n",
    "maximum = curry(tf.maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_tf(a, b):\n",
    "    return compose(\n",
    "        subtract_from(1.),\n",
    "        matmul(a),\n",
    "        tf.transpose,\n",
    "    )(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(outputs, alpha):\n",
    "    return compose(\n",
    "        maximum(0.),\n",
    "        tf.reduce_sum,\n",
    "        add(alpha),\n",
    "        subtract_from(cosine_distance_tf(outputs[0], outputs[1])),\n",
    "    )(\n",
    "        cosine_distance_tf(outputs[0], outputs[2]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_filename, input_name=\"images\", output_name=\"features\", alpha=0.):\n",
    "    with tf.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(file_handle.read())\n",
    "    \n",
    "    tf.import_graph_def(graph_def, name=\"net\")\n",
    "    \n",
    "    input_vars = []\n",
    "    output_vars = []\n",
    "    for i in range(3):\n",
    "        input_vars.append(tf.get_default_graph().get_tensor_by_name(\"net/%s:0\" % input_name))\n",
    "        output_vars.append(tf.get_default_graph().get_tensor_by_name(\"net/%s:0\" % output_name))\n",
    "        \n",
    "    cost = compute_cost(output_vars, alpha)\n",
    "    \n",
    "    return input_vars, output_vars, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, cost = load_model('./models/deep_sort_cnn/mars-small128.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input = inputs[0]\n",
    "single_output = outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(path, dirs, num_per_class):\n",
    "    \"\"\"\n",
    "    Get features from the base convolutional net for random images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path: string\n",
    "      Path to the image source on disk. \n",
    "      Source directory should be divided in directories, one directory per class.\n",
    "    - dirs: [string]\n",
    "      List of directories contained in the path. Correspond to classes.\n",
    "    - num_per_class: int\n",
    "      Number of images randomly chosen from each class\n",
    "      \n",
    "    Returns:\n",
    "    --------\n",
    "    - samples: ndarray (N, H, W, C)\n",
    "      Numpy array of randomly chosen images resized according to model's input shape.\n",
    "      N - number of samples\n",
    "      H - height\n",
    "      W - width\n",
    "      C - number odf channels\n",
    "    - features: ndarray (N, M)\n",
    "      Numpy array of features inferred by the base convolutional network from samples\n",
    "      N - number of samples\n",
    "      M - size of the convnet output\n",
    "    \"\"\"\n",
    "    \n",
    "    features = np.zeros((num_per_class * len(dirs), single_output.shape[1]))\n",
    "    samples = np.zeros((num_per_class * len(dirs), *single_input.shape[1:]))\n",
    "    \n",
    "    for i, dir_name in enumerate(tqdm(dirs)):\n",
    "        dir_path = os.path.join(path, dir_name)\n",
    "        filenames = os.listdir(dir_path)\n",
    "        filenames = np.random.choice(filenames, 10)\n",
    "        \n",
    "        batch = np.zeros((num_per_class, *single_input.shape[1:]))\n",
    "        \n",
    "        for j, filename in enumerate(filenames):\n",
    "            img = Image.open(os.path.join(dir_path, filename))\n",
    "            img = img.resize((single_input.shape[2], single_input.shape[1]))\n",
    "            img = np.array(img)\n",
    "            batch[j,:,:,:] = img\n",
    "        \n",
    "        batch_features = sess.run(single_output, {\n",
    "            single_input: batch,\n",
    "        })\n",
    "        \n",
    "        samples[i*num_per_class: i*num_per_class + num_per_class, :, :, :] = batch\n",
    "        features[i*num_per_class: i*num_per_class + num_per_class, :] = batch_features\n",
    "    \n",
    "    return samples, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(path, dirs, threshold, num_per_class, max_num_tiplets):\n",
    "    \"\"\"\n",
    "    Get batch of triplets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path: string\n",
    "      Path to the image source on disk. \n",
    "      Source directory should be divided in directories, one directory per class.\n",
    "    - dirs: [string]\n",
    "      List of directories contained in the path. Correspond to classes.\n",
    "    - threshold: float\n",
    "      Threshold that should divide positive and negative samples. \n",
    "      Used to choose ngative samples for training\n",
    "    - num_per_class: int\n",
    "      Number of images randomly chosen from each class\n",
    "    - max_num_tiplets: int\n",
    "      Maximum number of triplets per class. Actual number of triplets is max(max_num_tiplets, number of hard negatives)\n",
    "      \n",
    "    Returns:\n",
    "    --------\n",
    "    triplets: ndarry (N, 3, H, W, C)\n",
    "      Numpy array of randomly chosen triplets.\n",
    "      N - number of samples\n",
    "      3 - three samples: anchor, positive, negative\n",
    "      H - height\n",
    "      W - width\n",
    "      C - number odf channels\n",
    "    \"\"\"\n",
    "    \n",
    "    samples, features = forward_pass(path, dirs, num_per_class=num_per_class)\n",
    "    \n",
    "    triplets = []\n",
    "    for i in range(len(dirs)):\n",
    "        #get negative samples\n",
    "        negatives = []\n",
    "        index = np.random.randint(samples.shape[0])\n",
    "        for j in range(1000):\n",
    "            neg_index = np.random.randint(samples.shape[0])\n",
    "            if (abs(neg_index - index) >= num_per_class) & (cosine_distance(features[index,:], features[neg_index,:]) > threshold):\n",
    "                negatives.append(samples[neg_index,:,:,:])\n",
    "                if (len(negatives) == max_num_tiplets):\n",
    "                    break\n",
    "                    \n",
    "        #get positive samples\n",
    "        class_start_index = index - index % num_per_class\n",
    "        positives = []\n",
    "        while len(positives) < len(negatives):\n",
    "            for j in range(class_start_index, class_start_index + num_per_class):\n",
    "                if j != index:\n",
    "                    positives.append(samples[j,:,:,:])\n",
    "                    if len(positives) == len(negatives):\n",
    "                        break\n",
    "        \n",
    "        #get copies of anchor\n",
    "        anchor = np.zeros_like(negatives)\n",
    "        for j in range(len(negatives)):\n",
    "            anchor[j,:] = samples[index,:,:,:]\n",
    "            \n",
    "        triplets.append(np.stack([anchor, np.array(positives), np.array(negatives)], axis=1))\n",
    "    \n",
    "    return np.concatenate(triplets, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/mars/bbox_train/'\n",
    "dirs = compose(\n",
    "    filter_list(['.DS_Store'], False),\n",
    "    os.listdir,\n",
    ")(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_on_batch(path, dirs):\n",
    "    triplets = load_batch(path, dirs[0:5], threshold=0.2, num_per_class=20, max_num_tiplets=10)\n",
    "    \n",
    "    #sess.run([inputs, outputs, cost], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "learn_on_batch(path, dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
